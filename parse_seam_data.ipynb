{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as io\n",
    "from sklearn import preprocessing\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data directory\n",
    "# datadir = '/home/justin/Data/seam/'\n",
    "datadir = '/mnt/c/Users/Justin/Dropbox (Personal)/Shared/Haneet/Data/'\n",
    "d_train_f = datadir + 'training_data.mat'\n",
    "d_test_f = datadir + 'blind_data.mat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the matlab files for training and testing (blind) boreholes\n",
    "d_train = io.loadmat(d_train_f)\n",
    "d_test = io.loadmat(d_test_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the matlab data structures to get training/testing images and labels\n",
    "labels_train,images_train = d_train['ctrain'][0],d_train['dtrain'][0]\n",
    "labels_test,images_test = d_test['cblind'][0],d_test['dblind'][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ### INFO ###\n",
      "11 Training Data Boreholes\n",
      "5 Testing Data Boreholes\n",
      "4 Classes\n",
      "25 Values per Image (5 x 5)\n",
      "\n",
      "Borehole  1:  707 Depth Slices | Min: -19841.348   Max: 28279.582   Mean:  -10.96   Std: 4471.869\n",
      "Borehole  2:  689 Depth Slices | Min: -18987.617   Max: 27663.824   Mean:  -39.07   Std: 4270.490\n",
      "Borehole  3:  697 Depth Slices | Min: -14817.008   Max: 23764.441   Mean:   62.60   Std: 3502.549\n",
      "Borehole  4:  691 Depth Slices | Min: -17115.027   Max: 19057.191   Mean:   19.58   Std: 3449.588\n",
      "Borehole  5:  660 Depth Slices | Min: -18968.973   Max: 21860.555   Mean:    5.75   Std: 3506.990\n",
      "Borehole  6:  676 Depth Slices | Min: -18961.461   Max: 29092.922   Mean:  -12.60   Std: 4207.515\n",
      "Borehole  7:  702 Depth Slices | Min: -21064.227   Max: 30714.266   Mean:  -25.05   Std: 4467.483\n",
      "Borehole  8:  706 Depth Slices | Min: -19675.383   Max: 22419.102   Mean:   24.54   Std: 3528.093\n",
      "Borehole  9:  583 Depth Slices | Min: -12698.621   Max: 17069.480   Mean:  -47.61   Std: 3405.394\n",
      "Borehole 10:  665 Depth Slices | Min: -22542.320   Max: 23150.016   Mean: -102.55   Std: 4216.372\n",
      "Borehole 11:  669 Depth Slices | Min: -13712.184   Max: 11415.199   Mean:   25.67   Std: 3086.731\n"
     ]
    }
   ],
   "source": [
    "# Print some information\n",
    "print(' ### INFO ###')\n",
    "print('%i Training Data Boreholes' %(len(images_train)))\n",
    "print('%i Testing Data Boreholes' %(len(images_test)))\n",
    "print('%i Classes' %(labels_train[0].shape[0]))\n",
    "print('%i Values per Image (%i x %i)\\n'%(images_train[0].shape[0], np.sqrt(images_train[0].shape[0]), np.sqrt(images_train[0].shape[0])))\n",
    "\n",
    "cnt = 1\n",
    "for x,l in zip(images_train,labels_train):\n",
    "    xv = np.reshape(x,x.size)\n",
    "    print('Borehole %2i:  %i Depth Slices | Min: %-4.3f   Max: %-4.3f   Mean: % 7.2f   Std: %-4.3f' %(cnt, x.shape[1], xv.min(), xv.max(), xv.mean(), xv. std()))\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a plotting function\n",
    "def montageArray(x, img_size, ncol=50):\n",
    "    xx = np.reshape(x, (img_size,img_size,-1))\n",
    "    fig = plt.figure()\n",
    "    fig.set_size_inches(30,20)\n",
    "    fig.subplots_adjust(wspace=0.0)\n",
    "    n = xx.shape[2]\n",
    "    for i in range(n):   \n",
    "        a = fig.add_subplot(np.ceil(n/float(ncol)), ncol, i+1)\n",
    "        \n",
    "        plt.imshow(xx[:,:,i])\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the data\n",
    "montageArray(images_train[0],5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the labels to integers\n",
    "alllabels = []\n",
    "for label in labels_train:\n",
    "    l = [np.where(y)[0][0] for y in label.transpose()]\n",
    "    alllabels.append(torch.tensor(np.asarray(l)))\n",
    "    \n",
    "testlabels = []\n",
    "for label in labels_test:\n",
    "    l = [np.where(y)[0][0] for y in label.transpose()]\n",
    "    testlabels.append(torch.tensor(np.asarray(l)))\n",
    "    \n",
    "# print(alllabels)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the labels\n",
    "fig = plt.figure()\n",
    "for i,ll in enumerate(labels):\n",
    "    a = fig.add_subplot(1, len(labels), i+1)\n",
    "    plt.plot(100*ll,np.arange(len(ll)),'r.')\n",
    "    plt.axis('image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-8.227577091130255 3867.0146123165696 30714.265625 -22542.3203125\n",
      "1.0 -1.0 -0.15375376251665604 0.1452220244404986\n"
     ]
    }
   ],
   "source": [
    "# Normalize the data\n",
    "alldata = np.concatenate([x.flatten() for x in images_train])\n",
    "m,s,ma,mi = alldata.mean(),alldata.std(),alldata.max(),alldata.min()\n",
    "print(m,s,ma,mi)\n",
    "\n",
    "newd = 2*(alldata - mi)/(ma-mi)-1\n",
    "print(newd.max(),newd.min(),newd.mean(),newd.std())\n",
    "\n",
    "Ynorm = [2*(y-mi)/(ma-mi)-1 for y in images_train]\n",
    "Ynormtest = [2*(y-mi)/(ma-mi)-1 for y in images_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format the data and labels for PyTorch\n",
    "# Images should be formatted as [1,1,X,Y,Z] for each Borehole\n",
    "Ytrain = []\n",
    "for y in Ynorm:\n",
    "    Ytrain.append(torch.tensor(np.float32(np.reshape(y,(1,1,5,5,-1)))))\n",
    "    \n",
    "Ytest = []\n",
    "for y in Ynormtest:\n",
    "    Ytest.append(torch.tensor(np.float32(np.reshape(y,(1,1,5,5,-1)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3x3(x,K):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return F.conv3d(x, K, padding=1)\n",
    "\n",
    "def conv3x3x3T(x,K):\n",
    "    \"\"\"3x3 convolution transpose with padding\"\"\"\n",
    "    #K = torch.transpose(K,0,1)\n",
    "    return F.conv_transpose3d(x, K, padding=1)\n",
    "        \n",
    "        \n",
    "dis = nn.CrossEntropyLoss()\n",
    "def misfit(X,W,C):    \n",
    "    n = W.shape\n",
    "    X = X.view(-1,n[0])\n",
    "    S = torch.matmul(X,W)\n",
    "    return dis(S,C), S   \n",
    "\n",
    "def getAccuracy(S,labels):\n",
    "    _, predicted = torch.max(S.data, 1)\n",
    "    total = labels.size(0)\n",
    "    correct = (predicted == labels).sum().item()\n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, h,NG):\n",
    "        super().__init__()\n",
    "\n",
    "        # network geometry\n",
    "        self.NG       = NG\n",
    "        # time step\n",
    "        self.h        = h\n",
    "        # coarsening and TV norm\n",
    "        \n",
    "        \n",
    "    def forward(self,x,Kresnet):\n",
    "    \n",
    "        nt = len(Kresnet)\n",
    "        \n",
    "        # time stepping\n",
    "        for j in range(nt):\n",
    "            \n",
    "            # First case - rsent style step\n",
    "            if NG[0,j] == NG[1,j]: \n",
    "                #print(torch.norm(z))\n",
    "                z  = conv3x3x3(x, Kresnet[j])\n",
    "                z  = F.instance_norm(z)\n",
    "                z  = F.relu(z)        \n",
    "                z  = conv3x3x3T(z,Kresnet[j])\n",
    "                x  = x - self.h*z\n",
    "            # Change number of channels/resolution    \n",
    "            else:\n",
    "                z  = conv3x3x3(x, Kresnet[j])\n",
    "                z  = F.instance_norm(z)\n",
    "                x  = F.relu(z)\n",
    "        \n",
    "        # compress in x-y dimensions \n",
    "        #x = F.avg_pool3d(x, (5,5,1), stride=None, padding=0)\n",
    "             \n",
    "        return x #torch.transpose(p,0,1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Set up the GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize net and weights\n",
    "h           = 1e0\n",
    "\n",
    "# Network geometry\n",
    "NG = [1,    16,     16,    16,  \n",
    "      16,    16,     16,    16, \n",
    "      0,    0,     0,    0]\n",
    "\n",
    "NG = np.reshape(NG,(4,-1))\n",
    "\n",
    "\n",
    "net   = ResNet(h,NG)\n",
    "\n",
    "nsteps = NG.shape[1]\n",
    "\n",
    "\n",
    "Kresnet = []\n",
    "for i in range(nsteps):  \n",
    "    Ki  = nn.Parameter(torch.Tensor(np.asscalar(NG[1,i]), np.asscalar(NG[0,i]),3,3,3))\n",
    "    stdv  = 1e-3\n",
    "    Ki.data.uniform_(-stdv, stdv)    \n",
    "    # Move to the GPU\n",
    "    Ki.data = Ki.data.to(device)\n",
    "    \n",
    "    #print(torch.norm(Ki))\n",
    "    Kresnet.append(Ki)\n",
    "    \n",
    "# weights for linear classifier    \n",
    "W     = nn.Parameter(torch.Tensor(np.asscalar(NG[1,-1])*25,4))\n",
    "stdv  = 1e-3\n",
    "W.data.uniform_(-stdv, stdv)\n",
    "    \n",
    "# Move to GPU\n",
    "net.to(device)\n",
    "W.data = W.data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.SGD([{'params':Kresnet},{'params': W}], lr=5e-5, momentum=0.9)\n",
    "\n",
    "# Print every _ iterations\n",
    "p_iter = 1\n",
    "\n",
    "# Run _ epochs\n",
    "n_epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   Iteration   Loss(run)   Acc(run)   Acc(val)\n",
      "---------------------------------------------------\n",
      "  1          5        1.386      0.306      0.338\n",
      "  1          5        1.386      0.327      0.371\n",
      "  1          5        1.386      0.333      0.417\n",
      "  1          5        1.386      0.408      0.468\n",
      "  1          5        1.386      0.432      0.523\n",
      "  1          5        1.386      0.485      0.584\n",
      "  1          5        1.386      0.566      0.648\n",
      "  1          5        1.386      0.680      0.709\n",
      "  1          5        1.386      0.698      0.757\n",
      "  1          5        1.385      0.722      0.805\n",
      "  1          5        1.385      0.779      0.833\n",
      "Epoch   Iteration   Loss(run)   Acc(run)   Acc(val)\n",
      "---------------------------------------------------\n",
      "  2          5        1.385      0.755      0.855\n",
      "  2          5        1.385      0.821      0.869\n",
      "  2          5        1.385      0.824      0.887\n",
      "  2          5        1.385      0.858      0.902\n",
      "  2          5        1.384      0.864      0.912\n",
      "  2          5        1.384      0.848      0.920\n",
      "  2          5        1.384      0.875      0.928\n",
      "  2          5        1.383      0.938      0.931\n",
      "  2          5        1.383      0.921      0.933\n",
      "  2          5        1.382      0.881      0.936\n",
      "  2          5        1.383      0.891      0.940\n",
      "Epoch   Iteration   Loss(run)   Acc(run)   Acc(val)\n",
      "---------------------------------------------------\n",
      "  3          5        1.381      0.911      0.940\n",
      "  3          5        1.381      0.916      0.942\n",
      "  3          5        1.381      0.908      0.945\n",
      "  3          5        1.380      0.913      0.945\n",
      "  3          5        1.379      0.900      0.945\n",
      "  3          5        1.377      0.898      0.945\n",
      "  3          5        1.376      0.913      0.945\n",
      "  3          5        1.375      0.953      0.945\n",
      "  3          5        1.374      0.930      0.945\n",
      "  3          5        1.371      0.898      0.945\n",
      "  3          5        1.372      0.891      0.945\n",
      "Epoch   Iteration   Loss(run)   Acc(run)   Acc(val)\n",
      "---------------------------------------------------\n",
      "  4          5        1.367      0.918      0.945\n",
      "  4          5        1.365      0.925      0.945\n",
      "  4          5        1.364      0.908      0.945\n",
      "  4          5        1.361      0.915      0.945\n",
      "  4          5        1.358      0.900      0.945\n",
      "  4          5        1.354      0.898      0.945\n",
      "  4          5        1.349      0.913      0.945\n",
      "  4          5        1.346      0.953      0.945\n",
      "  4          5        1.343      0.930      0.945\n",
      "  4          5        1.336      0.898      0.945\n",
      "  4          5        1.336      0.891      0.945\n",
      "Epoch   Iteration   Loss(run)   Acc(run)   Acc(val)\n",
      "---------------------------------------------------\n",
      "  5          5        1.327      0.918      0.945\n",
      "  5          5        1.319      0.925      0.945\n",
      "  5          5        1.318      0.908      0.945\n",
      "  5          5        1.310      0.915      0.945\n",
      "  5          5        1.303      0.900      0.945\n",
      "  5          5        1.297      0.898      0.945\n",
      "  5          5        1.288      0.913      0.945\n",
      "  5          5        1.279      0.953      0.945\n",
      "  5          5        1.274      0.930      0.945\n",
      "  5          5        1.263      0.898      0.945\n",
      "  5          5        1.260      0.891      0.945\n",
      "Epoch   Iteration   Loss(run)   Acc(run)   Acc(val)\n",
      "---------------------------------------------------\n",
      "  6          5        1.251      0.918      0.945\n",
      "  6          5        1.237      0.925      0.945\n",
      "  6          5        1.231      0.908      0.945\n",
      "  6          5        1.220      0.915      0.945\n",
      "  6          5        1.210      0.900      0.945\n",
      "  6          5        1.210      0.898      0.945\n",
      "  6          5        1.197      0.913      0.945\n",
      "  6          5        1.176      0.953      0.945\n",
      "  6          5        1.170      0.930      0.945\n",
      "  6          5        1.163      0.898      0.945\n",
      "  6          5        1.153      0.891      0.945\n",
      "Epoch   Iteration   Loss(run)   Acc(run)   Acc(val)\n",
      "---------------------------------------------------\n",
      "  7          5        1.153      0.918      0.945\n",
      "  7          5        1.132      0.925      0.945\n",
      "  7          5        1.120      0.908      0.945\n",
      "  7          5        1.107      0.915      0.945\n",
      "  7          5        1.096      0.900      0.945\n",
      "  7          5        1.107      0.898      0.945\n",
      "  7          5        1.090      0.913      0.945\n",
      "  7          5        1.055      0.953      0.945\n",
      "  7          5        1.051      0.930      0.945\n",
      "  7          5        1.049      0.898      0.945\n",
      "  7          5        1.031      0.891      0.945\n",
      "Epoch   Iteration   Loss(run)   Acc(run)   Acc(val)\n",
      "---------------------------------------------------\n",
      "  8          5        1.043      0.918      0.945\n",
      "  8          5        1.016      0.925      0.945\n",
      "  8          5        0.998      0.908      0.945\n",
      "  8          5        0.986      0.915      0.945\n",
      "  8          5        0.975      0.900      0.945\n",
      "  8          5        0.999      0.898      0.945\n",
      "  8          5        0.977      0.913      0.945\n",
      "  8          5        0.930      0.953      0.945\n",
      "  8          5        0.931      0.930      0.945\n",
      "  8          5        0.934      0.898      0.945\n",
      "  8          5        0.908      0.891      0.945\n",
      "Epoch   Iteration   Loss(run)   Acc(run)   Acc(val)\n",
      "---------------------------------------------------\n",
      "  9          5        0.931      0.918      0.945\n",
      "  9          5        0.900      0.925      0.945\n",
      "  9          5        0.878      0.908      0.945\n",
      "  9          5        0.867      0.915      0.945\n",
      "  9          5        0.858      0.900      0.945\n",
      "  9          5        0.894      0.898      0.945\n",
      "  9          5        0.867      0.913      0.945\n",
      "  9          5        0.811      0.953      0.945\n",
      "  9          5        0.816      0.930      0.945\n",
      "  9          5        0.824      0.898      0.945\n",
      "  9          5        0.793      0.891      0.945\n",
      "Epoch   Iteration   Loss(run)   Acc(run)   Acc(val)\n",
      "---------------------------------------------------\n",
      " 10          5        0.826      0.918      0.945\n",
      " 10          5        0.792      0.925      0.945\n",
      " 10          5        0.766      0.908      0.945\n",
      " 10          5        0.759      0.915      0.945\n",
      " 10          5        0.751      0.900      0.945\n",
      " 10          5        0.797      0.898      0.945\n",
      " 10          5        0.767      0.913      0.945\n",
      " 10          5        0.701      0.953      0.945\n",
      " 10          5        0.713      0.930      0.945\n",
      " 10          5        0.725      0.898      0.945\n",
      " 10          5        0.691      0.891      0.945\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epoch):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_accuracy = 0.0\n",
    "    \n",
    "    print('Epoch   Iteration   Loss(run)   Acc(run)   Acc(val)')\n",
    "    print('---------------------------------------------------')\n",
    "    \n",
    "    for i in range(len(Ytrain)):\n",
    "        # get the inputs\n",
    "        inputs = Ytrain[i] \n",
    "        labels = alllabels[i]\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        x    = net(inputs,Kresnet)\n",
    "        loss, Si = misfit(x,W,labels)\n",
    "        loss.backward()\n",
    "             \n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        accuracy = getAccuracy(Si,labels)\n",
    "        running_loss     += loss.item()\n",
    "        running_accuracy += accuracy\n",
    "        if i % p_iter == (p_iter-1):    # print every p_iter mini-batches\n",
    "            # compute validation accuracy\n",
    "            with torch.no_grad():\n",
    "                for i in range(len(Ytest)):            \n",
    "                    #    dataiter = iter(testloader)\n",
    "                    #    inputsV, labelsV = dataiter.next()\n",
    "                    inputsV = Ytest[i] \n",
    "                    labelsV = testlabels[i]\n",
    "                    inputsV, labelsV = inputsV.to(device), labelsV.to(device)\n",
    "                    xV = net(inputsV,Kresnet)\n",
    "                    lossV, SiV = misfit(xV,W,labelsV)\n",
    "                    accuracyV  = getAccuracy(SiV,labelsV)\n",
    "\n",
    "#             accuracyV = 0\n",
    "            print(' %2d      %5d        %5.3f      %5.3f      %5.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / p_iter, running_accuracy/p_iter, accuracyV))\n",
    "            running_loss = 0.0\n",
    "            running_accuracy = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "x = net(Ytest[0],Kresnet)\n",
    "_,pred = misfit(x,W,testlabels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  0,  1,  1,  1,  1,  1,  1,  0,  1,  1,  0,\n",
       "         1,  1,  1,  0,  0,  0,  0,  0,  0,  1,  0,  1,  0,  1,\n",
       "         0,  0,  1,  1,  1,  1,  0,  0,  1,  1,  0,  1,  1,  1,\n",
       "         1,  0,  1,  0,  0,  1,  1,  0,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  0,\n",
       "         1,  0,  0,  1,  0,  0,  1,  0,  0,  0,  1,  1,  1,  0,\n",
       "         1,  1,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1], dtype=torch.uint8)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(pred.detach(),axis=1)==testlabels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
